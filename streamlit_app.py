import streamlit as st
import pandas as pd
import json
import re
import time
from selenium import webdriver
from selenium.webdriver.firefox.service import Service
from selenium.webdriver.firefox.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.firefox import GeckoDriverManager

# Pour tester branche

# ğŸ“Œ Chargement des compÃ©titions depuis un fichier CSV
def load_competitions_from_csv(csv_path="URL CompÃ©titions Football.csv"):
    try:
        competitions_df = pd.read_csv(csv_path)
        if "Pays" not in competitions_df.columns or "CompÃ©tition" not in competitions_df.columns or "URL" not in competitions_df.columns:
            st.error("âš ï¸ Le fichier CSV doit contenir les colonnes : 'Pays', 'CompÃ©tition', 'URL'.")
            return None
        st.session_state["competitions_df"] = competitions_df
        return competitions_df
    except Exception as e:
        st.error(f"âš ï¸ Erreur lors du chargement du fichier CSV : {e}")
        return None


# ğŸ“Œ Fonction d'initialisation du WebDriver
def init_driver():
    firefox_options = Options()
    firefox_options.add_argument("--headless")
    firefox_options.add_argument("--no-sandbox")
    firefox_options.add_argument("--disable-dev-shm-usage")

    service = Service(GeckoDriverManager().install())
    driver = webdriver.Firefox(service=service, options=firefox_options)
    return driver


# ğŸ“Œ Scraper les cotes d'une compÃ©tition (inchangÃ©)
def get_match_odds(competition_url, selected_bookmakers, nb_matchs):
    driver = init_driver()
    driver.get(competition_url)

    try:
        WebDriverWait(driver, 10).until(
            EC.presence_of_all_elements_located((By.TAG_NAME, "script"))
        )
    except:
        st.warning(f"âš ï¸ Aucun match trouvÃ© pour {competition_url}")
        return pd.DataFrame()

    scripts = driver.find_elements(By.TAG_NAME, "script")
    match_links = []

    for script in scripts:
        if '"@type":"SportsEvent"' in script.get_attribute("innerHTML"):
            try:
                json_data = json.loads(re.sub(r'[\x00-\x1F\x7F]', '', script.get_attribute("innerHTML")))
                if isinstance(json_data, dict) and "url" in json_data:
                    original_url = "https://www.coteur.com" + json_data["url"]
                    corrected_url = original_url.replace("/match/pronostic-", "/cote/")
                    match_links.append(corrected_url)
            except json.JSONDecodeError:
                continue

    match_links = match_links[:nb_matchs]
    all_odds = []

    for match_url in match_links:
        print(f"ğŸ” Scraping des cotes pour : {match_url}")
        driver.get(match_url)

        # ğŸ”„ VÃ©rifier que la page a bien changÃ© avant d'extraire les cotes
        previous_title = driver.title  # Stocke le titre prÃ©cÃ©dent

        for attempt in range(3):  # 3 tentatives max pour s'assurer que la page change
            time.sleep(3)  # Laisser le temps de chargement
            if driver.title != previous_title:
                print(f"âœ… Changement dÃ©tectÃ© -> Nouveau match : {driver.title}")
                break
            else:
                print("ğŸ”„ La page semble inchangÃ©e, tentative de rafraÃ®chissement...")
                driver.refresh()

        try:
            WebDriverWait(driver, 15).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, "div.bookline"))
            )
            time.sleep(3)  # DÃ©lai supplÃ©mentaire pour Ã©viter les pages incomplÃ¨tes
        except:
            st.warning(f"âš ï¸ Aucune cote trouvÃ©e pour {match_url}")
            continue

        odds_script = '''
        let oddsData = [];
        document.querySelectorAll("div.bookline").forEach(row => {
            let bookmaker = row.getAttribute("data-name");
            let odds = row.querySelectorAll("div.odds-col");
            let payoutElem = row.querySelector("div.border.bg-warning.payout");
            let payout = payoutElem ? payoutElem.innerText.trim() : "N/A";

            if (odds.length >= 3) {
                let odd_1 = odds[0].innerText.trim();
                let odd_n = odds[1].innerText.trim();
                let odd_2 = odds[2].innerText.trim();
                oddsData.push([bookmaker, odd_1, odd_n, odd_2, payout]);
            }
        });
        return oddsData;
        '''

        # ğŸ”„ Retenter jusqu'Ã  obtenir des cotes correctes
        max_retries = 3
        for attempt in range(max_retries):
            print(f"ğŸ”„ Tentative {attempt + 1} de rÃ©cupÃ©ration des cotes...")
            time.sleep(2)
            odds_list = driver.execute_script(odds_script)

            if odds_list:
                print(f"âœ… Cotes rÃ©cupÃ©rÃ©es : {odds_list}")
                break
            elif attempt < max_retries - 1:
                print("âš ï¸ Aucune cote dÃ©tectÃ©e, tentative de rafraÃ®chissement...")
                driver.refresh()
            else:
                print("âŒ Ã‰chec de la rÃ©cupÃ©ration des cotes aprÃ¨s plusieurs tentatives.")
                st.warning(f"âš ï¸ Impossible de rÃ©cupÃ©rer les cotes pour {match_url}")

        match_name = match_url.split("/")[-1].replace("-", " ").title()
        match_name = re.sub(r'\s*\d+#Cote\s*$', '', match_name).strip()

        for odd in odds_list:
            if odd[0] in selected_bookmakers:
                all_odds.append([match_name] + odd])

    driver.quit()

    return pd.DataFrame(all_odds, columns=["Match", "Bookmaker", "1", "Nul", "2", "Retour"])




# ğŸ“Œ Interface principale Streamlit
def main():
    st.set_page_config(page_title="Scraping des Cotes", page_icon="âš½", layout="wide")

    st.sidebar.title("ğŸ“Œ Menu")
    menu_selection = st.sidebar.radio("Choisissez un mode", ["ğŸ  Accueil", "âš½ Football", "ğŸ”‘ Admin"])

    if menu_selection == "ğŸ”‘ Admin":
        admin_password = st.sidebar.text_input("Mot de passe :", type="password")

        if admin_password == "gigtrading2025":
            st.sidebar.success("âœ… AccÃ¨s accordÃ©")
            st.title("ğŸ”§ Mode Administrateur")
            st.warning("ğŸ› ï¸ Pour l'instant, la partie Admin n'a pas d'action spÃ©cifique.")

    elif menu_selection == "âš½ Football":
        st.title("ğŸ“Š Scraping des Cotes Football")

        # ğŸ“Œ Chargement des compÃ©titions au dÃ©marrage
        if "competitions_df" not in st.session_state:
            load_competitions_from_csv()

        if "competitions_df" not in st.session_state or st.session_state["competitions_df"].empty:
            st.warning("âš ï¸ Aucune donnÃ©e en mÃ©moire. VÃ©rifiez le fichier CSV.")
        else:
            competitions_df = st.session_state["competitions_df"]
            selected_competitions = st.multiselect("ğŸ“Œ SÃ©lectionnez les compÃ©titions",
                                                   competitions_df["CompÃ©tition"].tolist())

            if selected_competitions:
                all_bookmakers = ["Winamax", "Unibet", "Betclic", "Pmu", "ParionsSport", "Zebet", "Olybet", "Bwin",
                                  "Vbet", "Genybet", "Feelingbet", "Betsson"]

                selected_bookmakers = st.multiselect("ğŸ° SÃ©lectionnez les bookmakers", all_bookmakers,
                                                     default=all_bookmakers)
                nb_matchs = st.slider("ğŸ”¢ Nombre de matchs par compÃ©tition", 1, 20, 5)

                if st.button("ğŸ” Lancer le scraping"):
                    with st.spinner("Scraping en cours..."):
                        all_odds_df = pd.concat([
                            get_match_odds(
                                competitions_df.loc[competitions_df["CompÃ©tition"] == comp, "URL"].values[0],
                                selected_bookmakers, nb_matchs
                            ) for comp in selected_competitions
                        ], ignore_index=True)

                    if not all_odds_df.empty:
                        all_odds_df["Retour"] = all_odds_df["Retour"].str.replace("%", "").str.replace(",", ".").astype(
                            float)

                        trj_mean = all_odds_df.groupby("Bookmaker")["Retour"].mean().reset_index()
                        trj_mean.columns = ["Bookmaker", "Moyenne TRJ"]
                        trj_mean = trj_mean.sort_values(by="Moyenne TRJ", ascending=False)
                        trj_mean["Moyenne TRJ"] = trj_mean["Moyenne TRJ"].apply(lambda x: f"{x:.2f}%")

                        trj_mean.index = trj_mean.index + 1

                        st.subheader("ğŸ“Š Moyenne des TRJ par opÃ©rateur")
                        st.dataframe(trj_mean)

                        st.subheader("ğŸ“Œ Cotes rÃ©cupÃ©rÃ©es")
                        st.dataframe(all_odds_df)


if __name__ == "__main__":
    main()
